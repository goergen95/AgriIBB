plot(randomPoints[c(33,34),])
mapview(randomPoints[c(33,34),])
mapview(randomPoints[c(62,71),])
randomPoints
which(index==2047)
which(index==2047)[seq(1,which(index==2047),2)]
which(index==2047)[seq(1,length(which(index==2047)),2)]
randomPoints[-which(index==2047)[seq(1,length(which(index==2047)),2)],]
randomPoints[-which(index==2047)[seq(1,length(which(index==2047)),2)],]
randomPoints = randomPoints[-which(index==2047)[seq(1,length(which(index==2047)),2)],]
buffer = gBuffer(randomPoints,byid = TRUE, width = 0.001475257*4.5)#width is 3 times pixel resolution)
notouch = gDisjoint(buffer, byid = TRUE)
index = apply(notouch,1,function(x){
return(sum(x))
})
index = as.vector(unlist(index))
unique(index)
gDisjoint()
?gDisjoint()
set.seed(123920)
randomPoints = lapply(provNames, function(x){
if(length(fields[which(fields$province==x),])==0) return(NULL)
tmp = spsample(fields[which(fields$province==x),],n=df$pixels[df$prov==x],"stratified")
return(tmp)
})
compact = function(x) Filter(Negate(is.null),x)
randomPoints = compact(randomPoints)
tmp = randomPoints[[1]]
for(i in 2:length(randomPoints)){
tmp = spRbind(tmp,randomPoints[[i]])
}
randomPoints = SpatialPointsDataFrame(tmp, data.frame(id=1:length(tmp)))
buffer = gBuffer(randomPoints,byid = TRUE, width = 0.001475257*4.5)#width is 3 times pixel resolution)
notouch = gDisjoint(buffer, byid = TRUE)
index = apply(notouch,1,function(x){
return(sum(x))
})
index = as.vector(unlist(index))
index = which(index==2047
index
index = which(index==2047)
index
notouch[index,]
which(!notouch)
which(notouch)
which(!notouch)
dim(which(!notouch))
index = apply(notouch,1,function(x){
return(which(x == FALSE))
})
index
index = as.vector(unlist(index))
index
randomPoints
index = apply(notouch,1,function(x){
if (sum(x)==0)return(0)
if (sum(x)>0)return(which(x)==FALSE)
})
index
notouch = gIntersect(buffer, byid = TRUE)
touch = gIntersects(buffer, byid = TRUE)
sum(touch[1,])
sum(touch[2,])
sum(touch[3,])
as.vector(touch[3,])
as.vector(touch[1,])
sum(touch[2,])
sum(touch[4,])
sum(touch[5,])
sum(touch[500,])
index = apply(touch,1,function(x){
if (sum(x)==1)return(0)
if (sum(x)>1)return(which(x)==TRUE)
})
index
index = as.vector(unlist(index))
index
which(index!=0)
index = apply(touch,1,function(x){
if (sum(x)==1)return(0)
if (sum(x)>1)return(which(x==TRUE))
})
index = as.vector(unlist(index))
which(index!=0)
index
?spsample
df$pixels = round(2500 * df$perc)
set.seed(123920)
randomPoints = lapply(provNames, function(x){
if(length(fields[which(fields$province==x),])==0) return(NULL)
tmp = spsample(fields[which(fields$province==x),],n=df$pixels[df$prov==x],"stratified")
return(tmp)
})
compact = function(x) Filter(Negate(is.null),x)
randomPoints = compact(randomPoints)
tmp = randomPoints[[1]]
for(i in 2:length(randomPoints)){
tmp = spRbind(tmp,randomPoints[[i]])
}
randomPoints = SpatialPointsDataFrame(tmp, data.frame(id=1:length(tmp)))
buffer = gBuffer(randomPoints,byid = TRUE, width = 0.001475257*4.5)#width is 3 times pixel resolution)
touch = gIntersects(buffer, byid = TRUE)
index = apply(touch,1,function(x){
if (sum(x)==1)return(0)
if (sum(x)>1)return(which(x==TRUE))
})
index = as.vector(unlist(index))
index
index = which(index!=0)
index
randomPoints = randomPoints[-index,]
randomPoints
writeOGR(tmp, dsn = "B:/ibb/results/shapes/random_points.shp",layer = "random_points",overwrite_layer = TRUE, driver ="ESRI Shapefile")
randomPoints = SpatialPointsDataFrame(randomPoints, data.frame(id=1:length(tmp)))
randomPoints = SpatialPointsDataFrame(randomPoints, data.frame(id=1:length(randomPoints)))
randomPoints
writeOGR(tmp, dsn = "B:/ibb/results/shapes/random_points.shp",layer = "random_points",overwrite_layer = TRUE, driver ="ESRI Shapefile")
writeOGR(tmp, dsn = "B:/ibb/results/shapes/random_points.shp",layer = "random_points",overwrite_layer = TRUE, driver ="ESRI Shapefile")
writeOGR(random, dsn = "B:/ibb/results/shapes/random_points.shp",layer = "random_points",overwrite_layer = TRUE, driver ="ESRI Shapefile")
writeOGR(randomPoints, dsn = "B:/ibb/results/shapes/random_points.shp",layer = "random_points",overwrite_layer = TRUE, driver ="ESRI Shapefile")
df
write.csv(df,"B:/ibb/results/randomSample.csv")
writeOGR(buffer, dsn = "B:/ibb/results/shapes/buffer.shp",layer = "buffer",overwrite_layer = TRUE, driver ="ESRI Shapefile")
install.packages("rater")
install.packages("raster")
library(raster)
first2016 = brick("B:/ibb/results/savG/savG_First2_2016.tif")
second2016 = brick("B:/ibb/results/savG/savG_Second2_2016.tif")
?merge
library(raster)
second2016 = brick("B:/ibb/results/savG/savG_Second2_2016.tif")
first2016 = brick("B:/ibb/results/savG/savG_First2_2016.tif")
?merge
t = merge(first2016,second2016)
t = mosaic(first2016,second2016)
second2016 = brick("B:/ibb/results/savG/savG_2003.tif")
library(raster)
second2016 = brick("B:/ibb/results/savG/savG_2003.tif")
second2016
plot(second2016[1],type = "l")
plot(as.numeric(second2016[1]),type = "l")
# script to prepare the training data
library(rgdal)
library(gdalUtils)
library(rgeos)
library(mapview)
library(sp)
library(maptools)
library(raster)
library(stringr)
randomPoints = readOGR("../results/shapes/random_points.shp")
regions = readOGR("../results/shapes/regions.shp")
fields = readOGR("../results/shapes/fields.shp")
interRegion = gIntersects(randomPoints,regions,byid=TRUE)
randomPoints
setwd("B:/ibb/AgriIBB/")
randomPoints = readOGR("../results/shapes/random_points.shp")
regions = readOGR("../results/shapes/regions.shp")
fields = readOGR("../results/shapes/fields.shp")
interRegion = gIntersects(randomPoints,regions,byid=TRUE)
# read in prediction data stored in spatial point data frame
points = readOGR("../results/shapes/random_points.shp")
# read in prediction data stored in spatial point data frame
points = readOGR("../results/shapes/random_points.shp")
predNames = readRDS("../results/prediction/predNames.rds")
# random sample 50 percent of points for training and validation
N0 = length(points@data$active[points@data$active==0])
N1 = length(points@data$active[points@data$active==1])
rfModel = readRDS("../results/prediction/rfModel.rds")
rfModel$trainingData
smp0 = sample(N0,0.5*N0)
smp0
N0
library(raster)
library(rgdal)
library(rgeos)
regions = readOGR("../results/shapes/regions.shp")
regionNames = unique(regions@data$NAME_2)
fields = readOGR("../results/shapes/fields.shp")
regions
names(regions)
content = gContains(regions,fields,byid=TRUE)
indexEmpty = as.vector(which(colSums(content)==0))
namesEmpty = regionNames[indexEmpty]
namesEmpty
indexEmpty
predfiles = list.files("../results/prediction/", pattern = "activitiy", full.names = T)
years = 2003:2016
dfActive = data.frame(active_2003=rep(0,14),
active_2004=rep(0,14),
active_2005=rep(0,14),
active_2006=rep(0,14),
active_2007=rep(0,14),
active_2008=rep(0,14),
active_2009=rep(0,14),
active_2010=rep(0,14),
active_2011=rep(0,14),
active_2012=rep(0,14),
active_2013=rep(0,14),
active_2014=rep(0,14),
active_2015=rep(0,14),
active_2016=rep(0,14))
dfActive
regionNames
dfActive = data.frame(regions=regionNames,
active_2003=rep(0,35),
active_2004=rep(0,35),
active_2005=rep(0,35),
active_2006=rep(0,35),
active_2007=rep(0,35),
active_2008=rep(0,35),
active_2009=rep(0,35),
active_2010=rep(0,35),
active_2011=rep(0,35),
active_2012=rep(0,35),
active_2013=rep(0,35),
active_2014=rep(0,35),
active_2015=rep(0,35),
active_2016=rep(0,35))
dfActive
dfInactive = data.frame(regions=regionNames,
inactive_2003=rep(0,35),
inactive_2004=rep(0,35),
inactive_2005=rep(0,35),
inactive_2006=rep(0,35),
inactive_2007=rep(0,35),
inactive_2008=rep(0,35),
inactive_2009=rep(0,35),
inactive_2010=rep(0,35),
inactive_2011=rep(0,35),
inactive_2012=rep(0,35),
inactive_2013=rep(0,35),
inactive_2014=rep(0,35),
inactive_2015=rep(0,35),
inactive_2016=rep(0,35))
region = dfActive$regions[1]
which(dfActive$regions==region)
dfActive[which(dfActive$regions==region),paste0("active_",year)]
year = 2003
dfActive[which(dfActive$regions==region),paste0("active_",year)]
for (year in years){
r = raster(predfiles[grep(year,predfiles)])
for (region in regionNames){
if(region %in% namesEmpty) next
print(region)
tmp = extract(r, regions[which(regions$NAME_2==region),], df=TRUE)
tmp = na.omit(tmp)
active = sum(tmp[,2]==2) * 6.25
inactive = sum(tmp[,2]==1) * 6.25
dfActive[which(dfActive$regions==region),paste0("active_",year)] = active
dfInactive[which(dfInactive$regions==region),paste0("inactive_",year)] = inactive
print(region)
}
print(paste0("Done with year ",year))
}
randomPoints = readOGR("../results/shapes/random_points.shp")
names(randomPoints)
randomPoints@data = randomPoints@data[,1:3]
names(randomPoints)
writeOGR(randomPoints,dsn="../data/shapes/random_points.shp",driver="ESRI Shapefile")
writeOGR(randomPoints,dsn="../data/shapes/random_points.shp",driver="ESRI Shapefile",layer="random_points")
writeOGR(randomPoints,dsn="../data/shapes/random_points.shp",driver="ESRI Shapefile",layer="random_points")
names(regions)
regions@data = regions@data[,c(1:3)]
writeOGR("../data/shapes/regions.shp")
writeOGR(dsn="../data/shapes/regions.shp")
writeOGR(dsn="../data/shapes/regions.shp",driver="ESRI Shapefile")
writeOGR(regions, dsn="../data/shapes/regions.shp",driver="ESRI Shapefile")
writeOGR(regions, dsn="../data/shapes/regions.shp",driver="ESRI Shapefile",layer="regions")
randomPoints = readOGR("../data/shapes/random_points.shp")
regions = readOGR("../data/shapes/regions.shp")
fields = readOGR("../data/shapes/fields.shp")
interRegion = gIntersects(randomPoints,regions,byid=TRUE)
# add region names to sample points
for (i in 1:length(randomPoints)){
randomPoints$region[i] = regions$NAME_2[interRegion[,i]]
print(i)
}
# prepare predictor stack based on DOY-NDVI values and growing season parameters
NDVI = stack(NDVIls)
GROW = stack(GROWls[grep("2016",list.files("../results/savG/",pattern=".tif"))])
NDVIls = list.files("../results/savG/layered/", pattern="2016", full.names=TRUE)
GROWls = list.files("../results/savG",pattern=".tif",full.names = TRUE)
# prepare predictor stack based on DOY-NDVI values and growing season parameters
NDVI = stack(NDVIls)
GROW = stack(GROWls[grep("2016",list.files("../results/savG/",pattern=".tif"))])
predStack = stack(NDVI,GROW)
rm(NDVI,GROW)
DOYs = paste("DOY",str_sub(NDVIls,-7,-5),sep="")
paras = c("AMP","MEAN","Q25","Q75","SD","SUM")
predNames = c(DOYs,paras)
saveRDS(predNames,file="../results/prediction/predNames.rds")
predNames
# transform fields and sample points to raster to speed up data extraction
r = raster("../results/savG/layered/savG_2003001.tif")
r[] = NA
refRas = rasterize(randomPoints,r,randomPoints$id)
writeRaster(refRas, "../results/prediction/refRas.tif")
refRas
writeRaster(refRas, "../results/prediction/refRas.tif", overwrite = TRUE)
# specifiy number of cores for parallell processing
cores = 7
# read in needed files
randomPoints = readOGR("../data/shapes/random_points.shp")
# adding region names to sample points
interRegion = gIntersects(randomPoints,regions,byid=TRUE)
for (i in 1:length(randomPoints)){
randomPoints$region[i] = regions$NAME_2[interRegion[,i]]
print(i)
}
# prepare predictor stack based on DOY-NDVI values and growing season parameters
NDVI = stack(NDVIls)
GROW = stack(GROWls[grep("2016",list.files("../results/savG/",pattern=".tif"))])
predStack = stack(NDVI,GROW)
rm(NDVI,GROW)
DOYs = paste("DOY",str_sub(NDVIls,-7,-5),sep="")
paras = c("AMP","MEAN","Q25","Q75","SD","SUM")
predNames = c(DOYs,paras)
saveRDS(predNames,file="../results/prediction/predNames.rds")
# transform fields and sample points to raster to speed up data extraction
r = raster("../results/savG/layered/savG_2003001.tif")
r[] = NA
refRas = rasterize(randomPoints,r,randomPoints$id)
writeRaster(refRas, "../results/prediction/refRas.tif", overwrite = TRUE)
?clusterR
?rasterize
# fields to raster (implemented with parallel processing)
fields$rasVal = 1
agrMask = raster("../results/prediction/agrMask.tif")
agrMask
beginCluster(cores)
agrMask = clusterR(y=r,fun = raster::rasterize,args=list(x=fields,field=fields$rasVal))
#agrMask = rasterize(fields,r,fields$rasVal)
endCluster()
beginCluster(cores)
agrMask = clusterR(r,fun=raster::rasterize,args=list(x=fields,field=fields$rasVal))
#agrMask = rasterize(fields,r,fields$rasVal)
endCluster()
plot(agrMask)
agrMask
writeRaster(agrMask,filename="../results/prediction/agrMask.tif", overwrite=TRUE)
# extract predictor variables for each pixel ID in refRas
names(predStack) = predNames
?getValues()
d = getValues(predStack,refRas)
refRas
d = predStack[refRas]
d
length(d)
length(d[1,])
length(d[,1])
predNames
randomPoints
which(is.na(randomPoints$active))
length(randomPoints$id)
names(da)
names(d)
head(d)
refRas
length(na.omit(values(refRas)))
# transform fields and sample points to raster to speed up data extraction
# sample points to raster
r = raster("../results/savG/layered/savG_2003001.tif")
r[] = NA
randomPoints
length(unique(randomPoints$id))
which(is.na(randomPoints$id))
refRas = rasterize(randomPoints,r,randomPoints$id)
length(na.omit(values(refRas)))
?rasterize
s = extract(refRas,randomPoints)
s
sum(is.na(s))
randomPoints
refRas = rasterize(randomPoints,r,randomPoints$id)
unique(values(refRas))
length(unique(values(refRas)))
rm(d)
data = predStack[refRas]
head(data)
length(data[,1])
?extract
which(!is.na(refRas))
which(!is.na(refRas)== 1)
!is.na(refRas)
Which(!is.na(refRas)==1)
?Which
Which(!is.na(refRas)==1, cells=TRUE)
length(Which(!is.na(refRas)==1, cells=TRUE))
length(na.omit(values(refRas)))
refRas = rasterize(randomPoints,r,randomPoints$id)
length(na.omit(values(refRas)))
randomPoints
refRas = rasterize(randomPoints,r,randomPoints$id, getCover=T)
length(na.omit(values(refRas)))
refRas = rasterize(randomPoints,r,randomPoints$id, na.rm=F)
length(na.omit(values(refRas)))
values(refRas)
na.omit(values(refRas))
x = na.omit(values(refRas))
y = seq(1,2515,1)
x[[1]]
as.vector(x)
x = as.vector(x)
which(x %in% y)
which(x %notin% y)
which(x %not% y)
which(y %in% x)
setdiff(y,x)
# read in needed files
randomPoints = readOGR("../data/shapes/random_points.shp")
randomPoints$id = 1:length(randomPoints$id)
writeOGR(randomPoints,dsn="../data/shapes/random_points.shp",driver="ESRI Shapefile",layer="random_points")
writeOGR(randomPoints,dsn="../data/shapes/random_points.shp",driver="ESRI Shapefile",layer="random_points",overwrite_layer = T)
# transform fields and sample points to raster to speed up data extraction
# sample points to raster
r = raster("../results/savG/layered/savG_2003001.tif")
r[] = NA
refRas = rasterize(randomPoints,r,randomPoints$id, na.rm=F)
length(na.omit(values(refRas)))
x = na.omit(values(refRas))
setdiff(y,x)
# read in needed files
randomPoints = readOGR("../data/shapes/random_points.shp")
# transform fields and sample points to raster to speed up data extraction
# sample points to raster
r = raster("../results/savG/layered/savG_2003001.tif")
r[] = NA
refRas = rasterize(randomPoints,r,randomPoints$id, na.rm=F)
writeRaster(refRas, "../results/prediction/refRas.tif", overwrite = TRUE)
# extract predictor variables for each pixel ID in refRas
names(predStack) = predNames
data = predStack[refRas]
head(data)
data[,predNames]
randomPoints@data[,predNames] = data[,predNames]
plot(colMeans(randomPoints@data[,predNames][which(randomPoints@data$active==0)]))
colMeans(randomPoints@data[,predNames])
plot(colMeans(randomPoints@data[which(randomPoints@data$active==0),predNames]))
plot(colMeans(randomPoints@data[which(randomPoints@data$active==0),predNames]),type = "l")
predNames
plot(colMeans(randomPoints@data[which(randomPoints@data$active==0),predNames[1:23]]),type = "l")
plot(colMeans(randomPoints@data[which(randomPoints@data$active==1),predNames[1:23]]),type = "l")
ids = na.omit(values(refRas))
ids
ids = as.vector(na.omit(values(refRas)))
ids
for(i in 1:length(ids)){
randomPoints@data[randomPoints$id==ids[i],predNames] = data[i,predNames]
}
plot(colMeans(randomPoints@data[which(randomPoints@data$active==1),predNames[1:23]]),type = "l")
plot(colMeans(randomPoints@data[which(randomPoints@data$active==0),predNames[1:23]]),type = "l")
head(randomPoints@data)
# save file to disk
writeOGR(randomPoints,dsn="../results/shapes/random_points.shp",overwrite_layer=TRUE,driver="ESRI Shapefile",layer="random_points")
# specifiy number of cores for parallell processing
cores = 7
# read in needed files
points = readOGR("../results/shapes/random_points.shp")
predNames = readRDS("../results/prediction/predNames.rds")
# randomly sample 50 percent of points for training and validation
# set seed is used to ensure reproducibility
N0 = length(points@data$active[points@data$active==0]) # number of inactive pixels
N1 = length(points@data$active[points@data$active==1]) # number of active pixels
set.seed(834289348)
smp0 = sample(N0,0.5*N0) # randomly select 50 percent of inactive pixels
set.seed(082345907234)
smp1 = sample(N1,0.5*N1) # randomly select 50 percent of active pixels
# randomly sample 50 percent of points for training and validation
# set seed is used to ensure reproducibility
N0 = length(points@data$active[points@data$active==0]) # number of inactive pixels
N1 = length(points@data$active[points@data$active==1]) # number of active pixels
set.seed(834289348)
smp0 = sample(N0,0.5*N0) # randomly select 50 percent of inactive pixels
set.seed(45907234)
smp1 = sample(N1,0.5*N1) # randomly select 50 percent of active pixels
# spliting the data in training and testing
training0 = points@data[which(points@data$active==0),][smp0,2:ncol(points@data)]
testing0 = points@data[which(points@data$active==0),][-smp0,2:ncol(points@data)]
training1 = points@data[which(points@data$active==1),][smp1,2:ncol(points@data)]
testing1= points@data[which(points@data$active==1),][-smp1,2:ncol(points@data)]
training = rbind(training0,training1)
testing = rbind(testing0,testing1)
rm(training0,training1,testing0,testing1)
# using the CAST package to achieve space-dependend folds for the cross-validation
index = CAST::CreateSpacetimeFolds(training,spacevar = "region",k=10,seed=320543)
tc = caret::trainControl(method="cv",number=10,classProbs = TRUE, index=index$index,indexOut=index$indexOut)
index
# using the CAST package to achieve space-dependend folds for the cross-validation
index = CAST::CreateSpacetimeFolds(training,spacevar = "region",k=35,seed=320543)
index
# using the CAST package to achieve space-dependend folds for the cross-validation
index = CAST::CreateSpacetimeFolds(training,spacevar = "region",k=10,seed=320543)
index
# ensure random forest is done as classification
training$active = make.names(training$active)
testing$active = make.names(testing$active)
# finally training the model, also with parallel processing to increase speed of computations
cl =  parallel::makeCluster(cores)
doParallel::registerDoParallel(cl)
rfModel = CAST::ffs(training[,predNames], training$active, method = "rf", withinSE = FALSE,importance = TRUE, trControl  = tc, metric = "Kappa")
# using the CAST package to achieve space-dependend folds for the cross-validation
index = CAST::CreateSpacetimeFolds(training,spacevar = "region",k=22,seed=320543)
tc = caret::trainControl(method="cv",number=22,classProbs = TRUE, index=index$index,indexOut=index$indexOut)
# ensure random forest is done as classification
training$active = make.names(training$active)
testing$active = make.names(testing$active)
# finally training the model, also with parallel processing to increase speed of computations
cl =  parallel::makeCluster(cores)
doParallel::registerDoParallel(cl)
rfModel = CAST::ffs(training[,predNames], training$active, method = "rf", withinSE = FALSE,importance = TRUE, trControl  = tc, metric = "Kappa")
endCluster()
